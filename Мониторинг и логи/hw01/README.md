**1.** Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?  

Минимальный набор метрик:  
> Инфраструктурные метрики:
- CPU Usage (% или load average) — так как вычисления нагружают CPU, это критично для понимания загруженности и планирования масштабирования.  
- RAM Usage — память также может быть бутылочным горлышком, особенно если задачи буферизуются в памяти.  
- Disk Space (Free/Used) — текстовые отчеты сохраняются на диск, если место закончится — платформа перестанет функционировать.  
- Disk I/O (черезput, latency) — если отчёты пишутся активно, может быть узким местом.  
- Inodes Usage — если много мелких файлов, может кончиться количество inodes, даже если место на диске есть.  

> Прикладные метрики:  
- HTTP Codes (2xx, 4xx, 5xx) — базовое понимание успешности и ошибок.  
- Request Latency (P50, P95, P99) — для оценки производительности.  
- Throughput (RPS) — количество запросов в секунду.  

**2.** Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

Менеджеру непонятны термины вроде RAM/inodes/CPUla. Ему нужно видеть метрики качества сервиса, которые отражают пользовательский опыт и выполнение обязательств.  
> Что можно предложить:  
- Uptime сервиса (доступность) — например, "99.95% за месяц".
-  Уровень SLA/SLO выполнения — процент запросов, обработанных успешно (например, "успешно обработаны 99% HTTP-запросов за последние 30 дней").
-  Ошибки на 1K запросов — сколько неудачных ответов на 1000 запросов.
-  Среднее время отклика — понятно и наглядно ("в среднем 200 мс").
-  Время генерации отчета — бизнес-метрика, напрямую относящаяся к конечному продукту.
-  Количество сгенерированных отчетов за период — отражает производительность системы.  
-  Нагрузка на пользователей (кол-во активных сессий, пользователей) — общая картина.  
-  Такие метрики понятны "не технарям" и показывают, как сервис выполняет свои обещания.  

**3.** Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

Если нет возможности построить полноценную систему (например, ELK/EFK stack, Loki, Graylog), можно использовать локальную запись логов + алертинг по файлам.  
> Возможные решения:  
-  Локальные логи + alerting через системный мониторинг  
   Настроить приложения так, чтобы они писали логи в локальные файлы (/var/log/app.log). Затем:  
   Подключить простые скрипты (например, tail -F + grep "ERROR" + email/slack уведомление).  
   Использовать systemd journal с фильтрацией по unit'ам.  
   Использовать fail2ban-like подход для обработки паттернов в логах.  
-  Log forwarding через syslog  
   Настроить приложение на отправку логов в syslog на ту же машину, а оттуда уже фильтровать (например, через rsyslog с mail-action).  
-  SSH-доступ и просмотр логов руками
   В крайнем случае дать разработчикам доступ (только на чтение) к логам на сервере.  
Таким образом, можно временно обойтись без полноценной системы сбора логов.

**4.** Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

Проблема в том, что помимо 2xx, 4xx и 5xx, есть другие HTTP коды, например:  
- 3xx (редиректы) — они НЕ относятся к успешным обработкам с точки зрения бизнес-логики, но технически это не ошибка.  
- 1xx (информационные)  
- 0xx или отсутствие ответа (если считаются запросы с обрывами или timeouts)  

**5.** Опишите основные плюсы и минусы pull и push систем мониторинга.  
> Pull-модель (мониторинг "тянет" метрики сам)  
➕ Плюсы:  
- Централизованный контроль: сервер мониторинга сам решает, что и когда опрашивать.  
- Проще управлять расписанием опроса (scrape interval).  
- Легче детектировать "мертвые" агенты — если нет ответа, сразу видно, что endpoint недоступен.  
- Меньше риска "залить" систему из-за большого количества агентов, которые могут одновременно пушить данные.  
➖ Минусы:  
- Трудности с метриками от динамически меняющихся/внешних компонентов (например, короткоживущие pods, временные инстансы, IoT-устройства за NAT).  
- Неудобно для сценариев, где объекты сами должны инициировать отправку данных (например, события).  

> Push-модель (агенты сами отправляют метрики на сервер)  
➕ Плюсы:
- Подходит для динамических или временных клиентов (например, контейнеры, мобильные устройства).  
- Легче масштабировать за счёт отсутствия постоянного опроса.  
- Устройства за NAT или с неизвестным IP могут самостоятельно отправлять данные.  
➖ Минусы:  
- Централизованному серверу сложнее понять, "жив" ли клиент — если агент перестал пушить, нужно отдельно настраивать heartbeat.  
- Сложнее управлять частотой отправки.  
- Потенциально сложнее контролировать нагрузку (если много агентов одновременно пушат).  

**6.** Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?  
Prometheus  
TICK  
Zabbix  
VictoriaMetrics  
Nagios

| Система             | Модель по умолчанию | Поддерживает push? | Итог                        |
| ------------------- | ------------------- | ------------------ | --------------------------- |
| **Prometheus**      | Pull                | Да (Pushgateway)   | Гибридная (основной — pull) |
| **TICK**            | Push (Telegraf)     | Да                 | Гибридная (основной — push) |
| **Zabbix**          | Pull                | Да                 | Гибридная                   |
| **VictoriaMetrics** | Зависит             | Да                 | Гибридная                   |
| **Nagios**          | Pull                | Да                 | Гибридная (основной — pull) |  

**7.** Склонируйте себе репозиторий и запустите TICK-стэк, используя технологии docker и docker-compose.  
<img width="1506" height="741" alt="image" src="https://github.com/user-attachments/assets/c74a3531-56b5-4612-86ab-906fb342ecc2" />  

**8.** Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.  
Изучите вывод интерфейса и выберите БД telegraf.autogen  
В measurments выберите cpu->host->telegraf-getting-started, а в fields выберите usage_system. Внизу появится график утилизации cpu.  
<img width="1553" height="755" alt="image" src="https://github.com/user-attachments/assets/9657272d-62e4-4e43-9505-3892405be439" />

**9.** Изучите список telegraf inputs. Добавьте в конфигурацию telegraf следующий плагин - docker:
<img width="1553" height="756" alt="image" src="https://github.com/user-attachments/assets/b6a7b797-9ae3-4e5e-b144-9d25df6aced1" />

